{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  - Predicting stock price is tricky. \n",
    "##  - THis is like a Time series problem.\n",
    "##  - Based on previous stock prices predicting the future stock price is not possible. \n",
    "##  - But usigt the previous stock price we can predict the trend\n",
    "##  - i.e We can predict wheather the trend is Upward or downward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training set\n",
    "dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "# we will load only training data set using this set we will train the model and use test data for predicting\n",
    "# Also the trained RNN Model will have no idea about test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.25],\n",
       "       [331.27],\n",
       "       [329.83],\n",
       "       ...,\n",
       "       [793.7 ],\n",
       "       [783.33],\n",
       "       [782.75]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "# Once loading training data we have to take the right column to bild model\n",
    "# Here we need only \"Open\" column from dataset. \"open\" measn stock price opened at that particular price for that day\n",
    "# [1:2] because we want to create an array of \"Open\" column in python upperbound(2nd column) is ignored\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to create NUMPY array of the column beacuse only Numpy array can be the input of Neural Network in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  - Feature Scaling \n",
    "### - THe two best ways of applying feature scaling is:-\n",
    "## 1 : Standerdization :  X(stand) = (X - Mean(X) / (std.dev(X))\n",
    "## 2 : Noramalization  : (X - Min(X) / (Max(X) - Min(X)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whenever we build RNN and espically we have sigmoid function in output layer of RNN, its better to use Normalization In RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range = (0, 1)) \n",
    "# All scaled values will be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368],\n",
       "       [0.09701243],\n",
       "       [0.09433366],\n",
       "       ...,\n",
       "       [0.95725128],\n",
       "       [0.93796041],\n",
       "       [0.93688146]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying SC object created on our dataset\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "# fit.transform applies Normalization formula to each observation\n",
    "#scaled data \n",
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Most imp step of data preprocesssing in RNN \n",
    "# 1. Create a timestep\n",
    "### - It is imp to have right number of time steps otherwise there will be overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -  We will create a timestep of 60 andd 1 output\n",
    "### - At each time T, RNN will look at 60 stock prizes before time T(60)\n",
    "### - And based on trends, it has captured during these 60 stock prizes(observations) it will try to predict the next output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Here 60 time step - 0th - 59th observation and 1 output - 60th observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First we will reate two empty entities\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60, 1258):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "# As the time step suitable here is 60, In order to get 60 previous stock prize we need to start with 60th observation \n",
    "#then only we will get 61st observation as output. so (60)\n",
    "#1258 last observation in training data\n",
    "# We want to append 1st 6o observation that means previous 60 stock price\n",
    "# 0 is the index of column in training_set_scaled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First valuse of i is 60\n",
    "# Using above formula = i-60:i, 0\n",
    "# 60 - 60 : 60 = 0 : 60  i.e 0 to 60 values i.e 0th observation to 59th observation\n",
    "# i =61 = 61-60 : 61 = 1: 61 Here we will have 59 observation in common and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i, 0] as i is 60, it will take 60th observation as predict output for 0-59 observation timesteps\n",
    "# Basically it is T+1 observation as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to build a  data struture\n",
    "# We have to make this X_train and Y_train to Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08581368 0.09701243 0.09433366 ... 0.07846566 0.08034452 0.08497656]\n",
      " [0.09701243 0.09433366 0.09156187 ... 0.08034452 0.08497656 0.08627874]\n",
      " [0.09433366 0.09156187 0.07984225 ... 0.08497656 0.08627874 0.08471612]\n",
      " ...\n",
      " [0.92106928 0.92438053 0.93048218 ... 0.95475854 0.95204256 0.95163331]\n",
      " [0.92438053 0.93048218 0.9299055  ... 0.95204256 0.95163331 0.95725128]\n",
      " [0.93048218 0.9299055  0.93113327 ... 0.95163331 0.95725128 0.93796041]]\n",
      "[0.08627874 0.08471612 0.07454052 ... 0.95725128 0.93796041 0.93688146]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is by using only \"open column\" we can use diff other column by doing same data preprocessing based on requirnment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the dataset\n",
    "### - Adding some more dimensionality to previous data struture\n",
    "### - \"open\" is only indicator we are using we can use more indicators for better prediction\n",
    "## - We use Reshape function not only to add more indicators or dimesionality\n",
    "## - But also to get suitable input format for RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - 3D tensor with shape (batch_size, timesteps, input_dim)\n",
    "#### using keras documentation we got this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### - This the input shape what RNN wants\n",
    "### - batch_size = Number of observation i.e number of stock prices\n",
    "### - timestep = no of time steps\n",
    "### - input_dim = no of indicators we want or using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.08581368],\n",
       "        [0.09701243],\n",
       "        [0.09433366],\n",
       "        ...,\n",
       "        [0.07846566],\n",
       "        [0.08034452],\n",
       "        [0.08497656]],\n",
       "\n",
       "       [[0.09701243],\n",
       "        [0.09433366],\n",
       "        [0.09156187],\n",
       "        ...,\n",
       "        [0.08034452],\n",
       "        [0.08497656],\n",
       "        [0.08627874]],\n",
       "\n",
       "       [[0.09433366],\n",
       "        [0.09156187],\n",
       "        [0.07984225],\n",
       "        ...,\n",
       "        [0.08497656],\n",
       "        [0.08627874],\n",
       "        [0.08471612]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.92106928],\n",
       "        [0.92438053],\n",
       "        [0.93048218],\n",
       "        ...,\n",
       "        [0.95475854],\n",
       "        [0.95204256],\n",
       "        [0.95163331]],\n",
       "\n",
       "       [[0.92438053],\n",
       "        [0.93048218],\n",
       "        [0.9299055 ],\n",
       "        ...,\n",
       "        [0.95204256],\n",
       "        [0.95163331],\n",
       "        [0.95725128]],\n",
       "\n",
       "       [[0.93048218],\n",
       "        [0.9299055 ],\n",
       "        [0.93113327],\n",
       "        ...,\n",
       "        [0.95163331],\n",
       "        [0.95725128],\n",
       "        [0.93796041]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "# X_train = Dataset we want to reshape\n",
    "# X_train.shape[0] will give no of observation from X_train data that is batch_size because [0] = rows\n",
    "# X_train.shape[1] will give no of time steps from X_train data that is [1] = columns\n",
    "# 1 no of indicator we are using \"open\"\n",
    "# One dimension for no of stock price \n",
    "# SEcond dimension for time steps\n",
    "# Third dimension for no of indicators or predictors\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Building the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialising the RNN\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "# units = No of LSTM cells or Neurons in first LSTM Layer\n",
    "# return_sequence = Used when we are building stacked(Many LSTM Layers) Lstm. We have to keep it true for building next Lstm layer\n",
    "# And false or leave default for las LSTM layer\n",
    "# input_shape = Shape of Input giving in First LSTM layer. Here we have to mention only timesteps and Indicators\n",
    "# No need to mention batch_size(No of observation ) as it will be given during fitting the model to dataset. \n",
    "# Dropout to avoid overfitting by ignoring two 20% of neurons for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-67f5a3872685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fitting the RNN to the Training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'regressor' is not defined"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Making the predictions and visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the real stock price of 2017\n",
    "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "# This is a test data i.e tock prices of Jan \n",
    "len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we have used 60 previous stock price to predict 61st observation , we need to do same in test data from taking 60 previous\n",
    "# Observation from training data\n",
    "#Here we need both training set and test set\n",
    "#Inorder to predict 2nd to last observation of test data we need that remaining previous test data to predict\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we need to Concatinate training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must not scale actual test values. \n",
    "# We will no concatinate the caled training values\n",
    "# We will concatinate the original(Not scaled) Values to test values\n",
    "#  we will get 60 previous values of stock price to predict and we will scale these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to scale this because we have built our RNN on this scaled values. We must use same scaling = \"NORMALIZATION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1278"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "# 1st argument = what we want to concatinate which column\"[open]\"\"(dataset_train['Open'], dataset_test['Open']\"\n",
    "# 2nd argumnet = concatinate rows or columns we want to concatinate ROWS so \"0\"\n",
    "# Now we got all values fro 2012 - 2017 of open column\n",
    "len(dataset_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([779.  , 779.66, 777.71, 786.66, 783.76, 781.22, 781.65, 779.8 ,\n",
       "       787.85, 798.24, 803.3 , 795.  , 804.9 , 816.68, 806.34, 801.  ,\n",
       "       808.35, 795.47, 782.89, 778.2 , 767.25, 750.66, 774.5 , 783.4 ,\n",
       "       779.94, 791.17, 756.54, 755.6 , 746.97, 755.2 , 766.92, 771.37,\n",
       "       762.61, 772.63, 767.73, 764.26, 760.  , 771.53, 770.07, 757.44,\n",
       "       744.59, 757.71, 764.73, 761.  , 772.48, 780.  , 785.04, 793.9 ,\n",
       "       797.4 , 797.34, 800.4 , 790.22, 796.76, 795.84, 792.36, 790.9 ,\n",
       "       790.68, 793.7 , 783.33, 782.75, 778.81, 788.36, 786.08, 795.26,\n",
       "       806.4 , 807.86, 805.  , 807.14, 807.48, 807.08, 805.81, 805.12,\n",
       "       806.91, 807.25, 822.3 , 829.62, 837.81, 834.71, 814.66, 796.86])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we want previous 60 stock prices from 1st observation of jan 2017\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "len(inputs)\n",
    "# 1278 - 20 - 60 : \n",
    "# Answer = from 1198th observation to last observation \" :\"\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1278 - 1198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[779.  ],\n",
       "       [779.66],\n",
       "       [777.71],\n",
       "       [786.66],\n",
       "       [783.76],\n",
       "       [781.22],\n",
       "       [781.65],\n",
       "       [779.8 ],\n",
       "       [787.85],\n",
       "       [798.24],\n",
       "       [803.3 ],\n",
       "       [795.  ],\n",
       "       [804.9 ],\n",
       "       [816.68],\n",
       "       [806.34],\n",
       "       [801.  ],\n",
       "       [808.35],\n",
       "       [795.47],\n",
       "       [782.89],\n",
       "       [778.2 ],\n",
       "       [767.25],\n",
       "       [750.66],\n",
       "       [774.5 ],\n",
       "       [783.4 ],\n",
       "       [779.94],\n",
       "       [791.17],\n",
       "       [756.54],\n",
       "       [755.6 ],\n",
       "       [746.97],\n",
       "       [755.2 ],\n",
       "       [766.92],\n",
       "       [771.37],\n",
       "       [762.61],\n",
       "       [772.63],\n",
       "       [767.73],\n",
       "       [764.26],\n",
       "       [760.  ],\n",
       "       [771.53],\n",
       "       [770.07],\n",
       "       [757.44],\n",
       "       [744.59],\n",
       "       [757.71],\n",
       "       [764.73],\n",
       "       [761.  ],\n",
       "       [772.48],\n",
       "       [780.  ],\n",
       "       [785.04],\n",
       "       [793.9 ],\n",
       "       [797.4 ],\n",
       "       [797.34],\n",
       "       [800.4 ],\n",
       "       [790.22],\n",
       "       [796.76],\n",
       "       [795.84],\n",
       "       [792.36],\n",
       "       [790.9 ],\n",
       "       [790.68],\n",
       "       [793.7 ],\n",
       "       [783.33],\n",
       "       [782.75],\n",
       "       [778.81],\n",
       "       [788.36],\n",
       "       [786.08],\n",
       "       [795.26],\n",
       "       [806.4 ],\n",
       "       [807.86],\n",
       "       [805.  ],\n",
       "       [807.14],\n",
       "       [807.48],\n",
       "       [807.08],\n",
       "       [805.81],\n",
       "       [805.12],\n",
       "       [806.91],\n",
       "       [807.25],\n",
       "       [822.3 ],\n",
       "       [829.62],\n",
       "       [837.81],\n",
       "       [834.71],\n",
       "       [814.66],\n",
       "       [796.86]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.reshape(-1,1)\n",
    "# To shape it as Numpy array\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling values to above SC object\n",
    "inputs = sc.transform(inputs)\n",
    "# Here we must not use fit method again\n",
    "# We must just use transform because it will scale same as it scaled training set\n",
    "# so both scaled values will be same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty entity\n",
    "X_test = []\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# From inputs append previous 60th observation to ith observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping same as above as 3D input for RNN\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAke prediction using predict method\n",
    "predicted_stock_price = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the predicted values are in scaled format\n",
    "# So we have to bring those scaled values back to origonal values\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')# Plotting real stock price with predicted stock price\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
